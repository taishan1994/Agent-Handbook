# 前言

过去一年，我们与数十个团队合作，跨行业构建大型语言模型（LLM）智能体。一贯以来，最成功的实现并非使用复杂的框架或专用库。相反，他们用简单、可组合的组件来构建。

在这篇文章中，我们将分享与客户及自己构建智能体合作的经验，并为开发者提供打造高效智能体的实用建议。

# 什么是智能体？

“智能体”可以有多种定义。一些客户将智能体定义为完全自主的系统，能够在较长时间内独立运行，使用各种工具完成复杂任务。也有人用该术语来描述遵循预定义工作流程的更具规范性的实现。在 Anthropic，我们将所有这些变体归类为**智能体系统** ，但在**工作流**和**智能体**之间划出一个重要的架构区分：

- **工作流**是通过预定义的代码路径协调 LLM 和工具的系统。
- 而**智能体**则是 LLM 动态指挥自身流程和工具使用，保持对任务完成方式的控制的系统。

下面我们将详细探讨这两种类型的能动系统。在附录1（“智能体实践”）中，我们描述了两个客户在使用此类系统中特别有价值的领域。

# 何时（何时不使用）智能体

在构建使用大型语言模型的应用时，我们建议尽量找到最简单的解决方案，只有在需要时才增加复杂度。这可能意味着根本不构建智能系统。智能系统通常会用延迟和成本来换取更好的任务性能，你应该考虑什么时候这种权衡才合适。

当需要更高复杂性时，工作流为明确定义的任务提供可预测性和一致性，而在大规模需要灵活性和模型驱动决策时，智能体是更好的选择。然而，对于许多应用来说，仅仅通过检索和上下文示例优化单个 LLM 调用通常就足够了。

# 何时以及如何使用框架

有许多框架使智能系统更容易实现，包括：

- [Claude 智能体 SDK](https://platform.claude.com/docs/en/agent-sdk/overview);
- 亚马逊 Bedrock 的 [AI 智能体框架 ](https://aws.amazon.com/bedrock/agents/);
- [Rivet](https://rivet.ironcladapp.com/)，一款拖拽式的图形用户界面大型语言模型工作流构建器;
- [Vellum](https://www.vellum.ai/)，另一个用于构建和测试复杂工作流的图形界面工具。

这些框架通过简化标准的底层任务，比如调用 LLM、定义和解析工具，以及串联调用，使入门变得非常简单。然而，它们通常会增加额外的抽象层，掩盖底层的提示和响应，使调试变得更困难。他们也可能让人想增加复杂的内容，而实际上更简单的设置就足够了。

我们建议开发者直接使用 LLM API：许多模式只需几行代码即可实现。如果你用框架，确保你理解底层代码。对底层的错误假设是客户常见的错误来源。

# 构建模块、工作流、智能体

在本节中，我们将探讨生产中常见的智能系统模式。我们将从基础构建块——增强型大型语言模型（LLM）开始，逐步增加复杂度，从简单的组合工作流程到自主智能体。

## 构建模块：增强型大型语言模型

智能体系统的基本构建模块是一个通过检索、工具和内存等增强功能增强的 LLM。我们现有的模型可以主动利用这些能力——生成自己的搜索查询，选择合适的工具，并确定需要保留哪些信息。

![img](./002.构建有效的智能体.assets/2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.webp)

我们建议重点关注实现的两个关键方面：根据您的具体用例定制这些能力，并确保它们为您的 LLM 提供一个简便且文档完善的界面。虽然实现这些增强有多种方式，但其中一种方法是通过我们最近发布的[模型上下文协议 ](https://www.anthropic.com/news/model-context-protocol)，它允许开发者通过简单的[客户端实现 ](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients)，与不断增长的第三方工具生态系统集成。

在本文剩余部分，我们假设每个 LLM 调用都能访问这些增强功能。

## 工作流：提示链

提示链将任务分解为一系列步骤，每个 LLM 调用处理前一个调用的输出。你可以在任何中间步骤添加程序检查（见下图中的“门”），以确保流程仍在正轨上。

![img](./002.构建有效的智能体.assets/2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.webp)

**何时使用此工作流：** 这种工作流非常适合任务可以轻松且干净地分解为固定子任务的情况。主要目标是通过降低延迟以获得更高的准确性，让每次调用都变得更轻松。

**提示链的实用示例：**

- 生成营销文案，然后将其翻译成另一种语言。
- 写一份文件的大纲，检查大纲是否符合某些标准，然后根据大纲写文件。

## 工作流：路由

路由对输入进行分类，并将其导向到专门的后续任务。这种工作流程允许关注点分离，并构建更专业的提示。没有这个工作流程，针对一种输入类型优化可能会影响其他输入的性能。

![img](./002.构建有效的智能体.assets/2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.webp)

**何时使用此工作程：** 路由适用于复杂任务，当有不同类别更适合单独处理，且分类可以通过大型语言模型或更传统的分类模型/算法准确处理时。

**路由有用的示例：**

- 将不同类型的客户服务问题（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具中。
- 将简单/常见问题分配到更小、成本效益高的模型，比如 Claude Haiku 4.5，把难题或特殊问题分配到功能更强的模型，比如 Claude Sonnet 4.5，以优化最佳性能。

## 工作流：并行化

LLM 有时可以同时处理同一任务，并以程序方式汇总输出。这种工作流程——并行化，体现在两种关键变体上：

- **分段** ：将任务拆分为独立的子任务并行执行。
- **投票：** 多次运行同一个任务以获得多样化的输出。

![img](./002.构建有效的智能体.assets/2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.webp)

**何时使用此工作流：** 当分开的子任务可以并行化以加快速度，或需要多角度或尝试以获得更高置信度时，并行化才有效。对于涉及多重考量的复杂任务，LLM 通常在每个考量由独立调用处理时表现更好，从而使每个具体方面能够集中注意力。

**并行化有用的示例：**

- **分段** ：
  - 实现保护栏，一个模型实例处理用户查询，另一个实例筛查不当内容或请求。这通常比让同一个 LLM 调用同时处理护栏和核心响应的表现更好。
  - 自动化评估用于评估 LLM 性能，即每次调用评估模型在特定提示符上表现的不同方面。
-  **投票：**
  - 审查一段代码是否有漏洞，多个不同的提示会在发现问题时进行审查并标记代码。
  - 评估某项内容是否不合适，多个提示词评估不同方面或要求不同的投票门槛，以平衡假阳性和阴性。

## 工作流：编排工作者

在编排者-工作者工作流中，中央的 LLM 动态拆解任务，委派给工作型 LLM 并综合其结果

![img](./002.构建有效的智能体.assets/2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.webp)

**何时使用此工作流：** 这种工作流程非常适合那些无法预测需要子任务的复杂任务（例如在编码中，需要更改的文件数量以及每个文件的变更性质很可能取决于任务）。虽然拓扑相似，但与并行化的关键区别在于灵活性——子任务不是预先定义的，而是由编排器根据具体输入决定的。

**编排工作者有用的示例：**

- Coding products that make complex changes to multiple files each time.
  那些每次对多个文件进行复杂修改的编码产品。
- Search tasks that involve gathering and analyzing information from multiple sources for possible relevant information.
  搜索涉及从多个来源收集和分析信息以寻找可能相关信息的任务。

## 工作流：评估器-优化器

在评估器-优化器工作流程中，一个 LLM 调用生成响应，另一个调用则在循环中提供评估和反馈。

![img](./002.构建有效的智能体.assets/2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.webp)

**何时使用此工作流：** 当我们有明确的评估标准，并且迭代优化能带来可衡量的价值时，这种工作流程尤其有效。良好契合的两个标志是：首先，当人类表达反馈时，LLM 的反应可以被明显提升;其次，LLM 能够提供此类反馈。这类似于人类写手在制作精致文档时可能经历的反复写作过程。

- 文学翻译中，有些细微差别是翻译者 LLM 一开始可能捕捉不到的，但评估者 LLM 可以提供有用的批评。
- 复杂的搜索任务需要多轮搜索和分析以收集全面信息，评估者决定是否需要进一步搜索。

## 智能体

随着 LLM 在关键能力上的成熟——理解复杂输入、进行推理和规划、可靠使用工具以及从错误中恢复——智能体正在生产环境中涌现。智能体从来自人类用户的指令或与其互动讨论开始工作。一旦任务明确，智能体们会独立规划和行动，可能会回访人类获取更多信息或判断。在执行过程中，智能体必须在每个步骤（如工具调用结果或代码执行）中获得环境的“地面真实信息”，以评估其进展。智能体可以在检查点或遇到阻碍时暂停等待人工反馈。任务通常在完成后终止，但通常也会包含停止条件（如最大迭代次数）以保持控制。

智能体可以处理复杂的任务，但其实现通常很简单。它们通常只是基于环境反馈的工具循环的大型语言模型。因此，清晰且深思熟虑地设计工具集及其文档至关重要。我们在附录2（“提示工程化你的工具”）中扩展了工具开发的最佳实践。

![img](./002.构建有效的智能体.assets/2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.webp)

**何时使用智能体：** 智能体可用于那些难以或不可能预测所需步骤数，且无法硬编码固定路径的开放式问题。LLM 可能会运行多回合，你必须对它的决策有一定信任。智能体的自主性使其非常适合在可信环境中扩展任务。

智能体的自主性意味着更高的成本，并且可能出现叠加错误。我们建议在沙盒环境中进行大量测试，并配合适当的防护措施。

**智能体的实用例子：**

以下示例来自我们自身的实现：

- 用于解析 [SWE 工作台任务](https://www.anthropic.com/research/swe-bench-sonnet)的编码智能体，这些任务涉及根据任务描述编辑多个文件;
- 我们的 [“计算机使用”参考实现 ](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)，Claude 利用计算机完成任务。

![img](./002.构建有效的智能体.assets/2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.webp)

# 组合和定制这些模式

这些构建模块并非强制性。它们是开发者可以塑造和组合以适应不同用例的常见模式。成功的关键，和任何大型语言模型功能一样，在于衡量性能并不断迭代实现。再说一遍： ***只有当它*明显改善了结果时，才应该考虑增加复杂度。**

# 总结

LLM 领域的成功并不是构建最复杂的系统。关键是为你打造适合你需求的*系统* 。从简单的提示开始，通过全面评估优化，只有在简单解决方案不足时才添加多步骤智能系统。

在实现智能体时，我们尽量遵循三个核心原则：

- 保持智能体设计**的简洁** 。
- 优先**透明，明确**展示智能体的规划步骤。
- 通过详尽的工具**文档和测试** ，精心打造您的智能体-计算机接口（ACI）。

框架可以帮助你快速入门，但不要犹豫，**在进入生产环境时减少抽象层，并用基础组件构建**。遵循这些原则，你可以创建不仅强大、可靠、易于维护且被用户信任的智能体。

> 原文链接：[构建高效的人工智能智能体 \ Anthropic --- Building Effective AI Agents \ Anthropic](https://www.anthropic.com/engineering/building-effective-agents)
>
> Written by Erik Schluntz and Barry Zhang. This work draws upon our experiences building agents at Anthropic and the valuable insights shared by our customers, for which we're deeply grateful.

# 附录1：智能体实践

我们与客户的合作揭示了两个对人工智能智能体特别有前景的应用，展示了上述模式的实际价值。这两个应用展示了客服如何在需要对话和行动的任务中为需要对话和行动的任务带来最大价值，拥有明确的成功标准，支持反馈循环，并整合有意义的人工监督。

## A. 经典支持

经典支持将熟悉的聊天机器人界面与通过工具集成增强的功能相结合。这对更开放的智能体人来说是自然的选择，因为:

- 支持互动自然遵循对话流程，同时需要获取外部信息和行动;
- 工具可以集成以提取客户数据、订单历史和知识库文章;
- 诸如发放退款或更新工单等作可以通过程序化处理;;
- 成功可以通过用户定义的分辨率来明确衡量。

多家公司通过基于使用量的定价模式，仅对成功解决方案收费，展示了这种方法的可行性，显示出对其智能体有效性的信心。

## B. 编码智能体

软件开发领域展现出 LLM 功能的巨大潜力，能力从代码完成向自主问题解决不断发展。智能体特别有效，因为：

- 代码解决方案可通过自动化测试验证;
- 智能体可以利用测试结果作为反馈来迭代解;
- 问题空间定义明确且结构清晰;
- 输出质量可以客观地衡量。

在我们自己的实现中，智能体现在仅凭拉取请求描述就能在 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准测试中解决真正的 GitHub 问题。然而，自动化测试有助于验证功能，人工审核对于确保解决方案符合更广泛的系统需求仍然至关重要。

# 附录2：提示工程化你的工具

无论你构建的是哪种智能体系统，工具很可能都是智能体的重要组成部分。工具[使 ](https://www.anthropic.com/news/tool-use-ga)Claude 能够通过在 API 中指定其具体结构和定义，与外部服务和 API 交互。当 Claude 响应时，如果计划调用某个工具，它会在 API 响应中包含[一个工具使用块 ](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-api-response-with-a-tool-use-content-block)。工具定义和规格应与整体提示词同等重视提示工程。在本简短附录中，我们介绍了如何为你的工具进行提示工程。

通常有多种方式可以指定同一个动作。例如，你可以通过写入差异来指定文件编辑，或者重写整个文件。对于结构化输出，你可以返回 markdown 或 JSON 代码。在软件工程中，这些差异只是表面上的，可以无损地从一个转换到另一个。然而，有些格式对大型语言模型来说比其他格式更难编写。写差别需要在写新代码之前知道区块头中有多少行发生变化。在 JSON 里写代码（相比 markdown）需要额外的换行和引号转义。

我们关于选择工具格式的建议如下：

- 给模型足够的token让它“思考”，然后再写入某个角落。
- 保持格式接近模型在网络文本中自然看到的样子。
- 确保没有格式上的“开销”，比如必须精确统计成千上万行代码，或者写出的代码会跳出字符串。

一个经验法则是考虑人机界面（HCI）投入了多少精力，并计划投入同样的精力打造优秀的*智能体* -计算机接口（ACI）。以下是一些关于如何实现的想法：

- 设身处地为模型着想。根据描述和参数，这个工具的使用方式是否很明显，还是需要仔细思考？如果是这样，那模型大概也同样适用。一个良好的工具定义通常包括示例使用情况、边缘情况、输入格式要求以及与其他工具的明确界限。
- 你如何更改参数名称或描述，使事情更明显？可以把这看作是为团队中的初级开发者写一份很棒的文件字符串。这在使用许多类似工具时尤为重要。
- 测试模型如何使用你的工具：在我们的[工作台](https://console.anthropic.com/workbench)中运行多个示例输入，看看模型犯了哪些错误，并不断迭代。
- 用 [“Poka-yole”把工具带进](https://en.wikipedia.org/wiki/Poka-yoke)去。改变论点，使犯错更难。

在为 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 构建智能体时，我们实际上花在优化工具上的时间比整体提示还多。例如，我们发现模型在智能体离开根目录后，使用相对文件路径的工具时会出现错误。为了解决这个问题，我们将工具改为始终要求绝对文件路径——结果发现模型在使用这种方法时非常完美。