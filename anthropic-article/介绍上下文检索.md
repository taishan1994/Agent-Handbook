# 前言

为了让 AI 模型在特定情境下发挥作用，通常需要获得背景知识。例如，客户支持聊天机器人需要了解其所服务的具体业务，而法律分析机器人则需要了解大量过去案件。

开发者通常通过检索增强生成（RAG）来增强 AI 模型的知识。RAG 是一种从知识库中提取相关信息并将其附加到用户提示词中的方法，显著提升模型的响应能力。问题在于，传统的 RAG 解决方案在编码信息时会去除上下文，这常常导致系统无法从知识库中检索相关信息。

本文概述了一种显著改善 RAG 检索步骤的方法。该方法称为“上下文检索”，采用两个子技术：上下文嵌入和上下文 BM25。该方法可将失败检索次数减少 49%，结合重新排序则减少 67%。这些都显著提升了检索精度，直接转化为下游任务的更好表现。

# 关于简单使用更长提示的说明

有时候，最简单的解决方案就是最好的。如果你的知识库小于 20 万个 token（约 500 页材料），你可以直接把整个知识库写进给模型的提示词里，无需 RAG 或类似方法。然而，随着知识库的增长，你需要一个更具可扩展性的解决方案。这就是情境检索发挥作用的地方。

# RAG 入门：扩展到更大规模的知识库

对于不适合上下文窗口的大型知识库，RAG 是典型的解决方案。RAG 通过预处理知识库，步骤如下：
- 将知识库（文档的“语料库”）拆分成更小的文本块，通常不超过几百个标记;
- 使用嵌入模型将这些块转换为编码意义的向量嵌入;
- 将这些嵌入存储在一个矢量数据库中，允许通过语义相似性进行搜索。

运行时，当用户向模型输入查询时，向量数据库会根据与查询的语义相似性找到最相关的块。然后，最相关的片段被添加到发送给生成模型的提示中

虽然嵌入模型擅长捕捉语义关系，但它们可能会遗漏关键的精确匹配。幸运的是，有一种较早的技术可以帮助解决这些情况。BM25（最佳匹配 25）是一种排名函数，利用词汇匹配来寻找精确的词语或短语匹配。它对包含唯一标识符或技术术语的查询尤其有效。

BM25 的工作原理是基于 TF-IDF（术语频率-逆文档频率）概念。TF-IDF 衡量一个词对集合中文档的重要性。BM25 通过考虑文档长度并对词频应用饱和函数来改进，有助于防止常用词占据结果。

以下是 BM25 在语义嵌入无法成功的地方的成功方式：假设用户在技术支持数据库中查询“错误代码 TS-999”。嵌入模型可能会找到关于错误码的一般内容，但可能会错过准确的“TS-999”匹配。BM25 会寻找这串特定的文本字符串来识别相关文档。

通过结合嵌入和 BM25 技术，RAG 解决方案可以通过以下步骤更准确地检索最适用的块：
- 将知识库（文档的“语料库”）拆分成更小的文本块，通常不超过几百个标记;
- 为这些块创建 TF-IDF 编码和语义嵌入;
- 用 BM25 根据精确匹配找到顶层块;
- 利用嵌入根据语义相似性查找顶部块;
- 利用秩融合技术组合和去重（3）和（4）的结果;
- 将前 K 块添加到提示中以生成响应。

通过结合 BM25 和嵌入模型，传统 RAG 系统能够提供更全面、更准确的结果，在精确术语匹配与更广泛的语义理解之间取得平衡。



