"""
äººæœºååŒæ¨¡å¼èŠ‚ç‚¹å®ç°

æœ¬æ¨¡å—åŒ…å«äº†äººæœºååŒæ¨¡å¼æ‰€éœ€çš„å„ç§èŠ‚ç‚¹å®ç°ï¼ŒåŒ…æ‹¬ï¼š
- TaskProcessor: å¤„ç†åˆå§‹ä»»åŠ¡
- HumanEscalation: å¤„ç†éœ€è¦äººå·¥å¹²é¢„çš„æƒ…å†µ
- HumanInput: æ¥æ”¶å’Œå¤„ç†äººç±»è¾“å…¥
- ResponseGenerator: ç”Ÿæˆæœ€ç»ˆå“åº”
"""

import sys
import os
import time
import random
from typing import Dict, Any, Optional, List

# æ·»åŠ utilsè·¯å¾„
utils_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'utils'))
if utils_path not in sys.path:
    sys.path.append(utils_path)

# æ·»åŠ PocketFlowè·¯å¾„
pocketflow_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if pocketflow_path not in sys.path:
    sys.path.append(pocketflow_path)

try:
    from pocketflow import Node
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥PocketFlowï¼Œä½¿ç”¨æ¨¡æ‹ŸNodeç±»")
    class Node:
        def __init__(self, name: str = ""):
            self.name = name
            self.successors = {}
            self.params = {}
        
        def set_params(self, params):
            self.params = params
        
        def prep(self, shared):
            return None
        
        def exec(self, prep_res):
            return f"{self.name}_action"
        
        def post(self, shared, prep_res, exec_res):
            return exec_res
        
        def next(self, node, action="default"):
            self.successors[action] = node
            return node
        
        def __rshift__(self, other):
            return self.next(other)

try:
    from call_llm import call_llm
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥call_llmï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‡½æ•°")
    def call_llm(prompt: str, model: str = "default") -> str:
        # ç®€å•çš„æ¨¡æ‹ŸLLMå“åº”ï¼ŒåŸºäºæç¤ºè¯ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„å†…å®¹
        if "å¤©æ°”" in prompt:
            return "æ ¹æ®æœ€æ–°æ°”è±¡æ•°æ®ï¼Œæ˜å¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©åœ¨15-25æ‘„æ°åº¦ä¹‹é—´ï¼Œå¾®é£ï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚"
        elif "é¡¹ç›®è®¡åˆ’" in prompt and "å¤šéƒ¨é—¨" in prompt:
            return "é’ˆå¯¹æ‚¨çš„å¤šéƒ¨é—¨åä½œé¡¹ç›®è®¡åˆ’ï¼Œå»ºè®®å¦‚ä¸‹ï¼š1) æˆç«‹è·¨éƒ¨é—¨é¡¹ç›®ç»„ï¼Œæ˜ç¡®å„éƒ¨é—¨èŒè´£ï¼›2) åˆ¶å®šè¯¦ç»†æ—¶é—´è¡¨ï¼Œè®¾ç½®å…³é”®é‡Œç¨‹ç¢‘ï¼›3) å»ºç«‹å®šæœŸæ²Ÿé€šæœºåˆ¶ï¼Œç¡®ä¿ä¿¡æ¯åŒæ­¥ï¼›4) é¢„ç•™åº”æ€¥é¢„ç®—ï¼Œåº”å¯¹å¯èƒ½çš„é£é™©ã€‚"
        elif "äººç±»ä¸“å®¶" in prompt:
            return "åŸºäºäººç±»ä¸“å®¶çš„å»ºè®®ï¼Œæˆ‘å·²æ•´åˆå‡ºä»¥ä¸‹æ–¹æ¡ˆï¼šé¦–å…ˆåˆ†æä»»åŠ¡æ ¸å¿ƒéœ€æ±‚ï¼Œç„¶ååˆ¶å®šè¯¦ç»†è®¡åˆ’ï¼Œåˆ†æ­¥éª¤æ‰§è¡Œå¹¶è®¾ç½®æ£€æŸ¥ç‚¹ã€‚å¯¹äºæ¶‰åŠå¤šéƒ¨é—¨åä½œçš„ä»»åŠ¡ï¼Œå»ºè®®æˆç«‹ä¸“é—¨é¡¹ç›®ç»„ï¼Œç¡®ä¿å„éƒ¨é—¨æœ‰æ•ˆæ²Ÿé€šå’Œåä½œã€‚"
        else:
            return "æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘å·²ç»åˆ†æäº†ç›¸å…³ä¿¡æ¯å¹¶åˆ¶å®šäº†ç›¸åº”çš„å¤„ç†æ–¹æ¡ˆã€‚å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´ï¼Œè¯·éšæ—¶å‘ŠçŸ¥ã€‚"

try:
    from exa_search_main import search_web_exa
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥search_web_exaï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‡½æ•°")
    def search_web_exa(query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        return [
            {"title": f"æ¨¡æ‹Ÿæœç´¢ç»“æœ {i+1}", "url": f"https://example.com/{i+1}", "snippet": f"æ¨¡æ‹Ÿæœç´¢æ‘˜è¦ {i+1}"}
            for i in range(num_results)
        ]


class TaskProcessor(Node):
    """ä»»åŠ¡å¤„ç†å™¨èŠ‚ç‚¹ï¼Œè´Ÿè´£å¤„ç†åˆå§‹ä»»åŠ¡"""
    
    def __init__(self, complexity_threshold: float = 0.7):
        """
        åˆå§‹åŒ–ä»»åŠ¡å¤„ç†å™¨
        
        Args:
            complexity_threshold: å¤æ‚åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼éœ€è¦äººå·¥å¹²é¢„
        """
        super().__init__()
        self.complexity_threshold = complexity_threshold
    
    def prep(self, shared):
        """å‡†å¤‡é˜¶æ®µï¼šè·å–ä»»åŠ¡ä¿¡æ¯"""
        task = shared.get("task", "")
        print(f"ğŸ”§ TaskProcessor: å¼€å§‹å¤„ç†ä»»åŠ¡")
        print(f"ğŸ“ ä»»åŠ¡å†…å®¹: {task}")
        return {"task": task}
    
    def exec(self, prep_res):
        """æ‰§è¡Œé˜¶æ®µï¼šè¯„ä¼°å¤æ‚åº¦å¹¶å†³å®šå¤„ç†æ–¹å¼"""
        task = prep_res.get("task", "")
        
        # æ¨¡æ‹Ÿä»»åŠ¡å¤æ‚åº¦è¯„ä¼°
        complexity = self._assess_complexity(task)
        print(f"ğŸ“Š ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°: {complexity:.2f} (é˜ˆå€¼: {self.complexity_threshold})")
        
        # å†³å®šå¤„ç†æ–¹å¼
        if complexity < self.complexity_threshold:
            return {
                "action": "auto_processed",
                "complexity": complexity,
                "requires_human_intervention": False
            }
        else:
            return {
                "action": "escalate_to_human",
                "complexity": complexity,
                "requires_human_intervention": True,
                "escalation_reason": f"ä»»åŠ¡å¤æ‚åº¦({complexity:.2f})è¶…è¿‡é˜ˆå€¼({self.complexity_threshold})"
            }
    
    def post(self, shared, prep_res, exec_res):
        """åå¤„ç†é˜¶æ®µï¼šæ›´æ–°å…±äº«çŠ¶æ€å¹¶å¤„ç†ä»»åŠ¡"""
        task = prep_res.get("task", "")
        action = exec_res.get("action")
        complexity = exec_res.get("complexity")
        
        # æ›´æ–°å…±äº«æ•°æ®
        shared["task_complexity"] = complexity
        shared["requires_human_intervention"] = exec_res.get("requires_human_intervention", False)
        
        if action == "auto_processed":
            print("âœ… TaskProcessor: ä»»åŠ¡å¤æ‚åº¦è¾ƒä½ï¼Œå°è¯•è‡ªåŠ¨å¤„ç†")
            result = self._process_task(task, shared)
            shared["task_result"] = result
        else:
            print("âš ï¸ TaskProcessor: ä»»åŠ¡å¤æ‚åº¦è¿‡é«˜ï¼Œéœ€è¦äººå·¥å¹²é¢„")
            shared["escalation_reason"] = exec_res.get("escalation_reason", "")
        
        return action
    
    def _assess_complexity(self, task: str) -> float:
        """
        è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦
        
        Args:
            task: ä»»åŠ¡æè¿°
            
        Returns:
            float: å¤æ‚åº¦åˆ†æ•° (0-1)
        """
        # ç®€å•çš„å¤æ‚åº¦è¯„ä¼°é€»è¾‘
        complexity_indicators = [
            "å¤æ‚", "å›°éš¾", "æŒ‘æˆ˜", "å¤šæ­¥éª¤", "è·¨éƒ¨é—¨", "æ•æ„Ÿ", "é«˜é£é™©",
            "é“å¾·", "ä¼¦ç†", "æ³•å¾‹", "å®‰å…¨", "éšç§", "ç´§æ€¥", "å±æœº"
        ]
        
        base_complexity = 0.3  # åŸºç¡€å¤æ‚åº¦
        
        # æ ¹æ®å…³é”®è¯å¢åŠ å¤æ‚åº¦
        for indicator in complexity_indicators:
            if indicator in task:
                base_complexity += 0.1
        
        # æ ¹æ®ä»»åŠ¡é•¿åº¦å¢åŠ å¤æ‚åº¦
        length_factor = min(len(task) / 200, 0.3)
        base_complexity += length_factor
        
        # æ·»åŠ ä¸€äº›éšæœºæ€§
        random_factor = random.uniform(-0.05, 0.05)
        base_complexity += random_factor
        
        # ç¡®ä¿å¤æ‚åº¦åœ¨0-1èŒƒå›´å†…
        return max(0.1, min(1.0, base_complexity))
    
    def _process_task(self, task: str, shared_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è‡ªåŠ¨å¤„ç†ä»»åŠ¡
        
        Args:
            task: ä»»åŠ¡æè¿°
            shared_data: å…±äº«æ•°æ®å­—å…¸
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœ
        """
        print("ğŸ” TaskProcessor: æœç´¢ç›¸å…³ä¿¡æ¯...")
        search_results = search_web_exa(task)
        
        print("ğŸ¤– TaskProcessor: ç”Ÿæˆä»»åŠ¡å¤„ç†æ–¹æ¡ˆ...")
        prompt = f"""
        ä»»åŠ¡: {task}
        
        å‚è€ƒä¿¡æ¯:
        {search_results}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºè¿™ä¸ªä»»åŠ¡æä¾›ä¸€ä¸ªå®Œæ•´çš„å¤„ç†æ–¹æ¡ˆã€‚
        """
        
        response = call_llm(prompt)
        
        return {
            "status": "completed",
            "response": response,
            "search_results": search_results,
            "processing_time": time.time()
        }


class HumanEscalation(Node):
    """äººå·¥å‡çº§èŠ‚ç‚¹ - å¤„ç†éœ€è¦äººå·¥å¹²é¢„çš„æƒ…å†µ"""
    
    def __init__(self):
        super().__init__()
    
    def prep(self, shared):
        """å‡†å¤‡é˜¶æ®µï¼šè·å–å‡çº§ä¿¡æ¯"""
        task = shared.get("task", "")
        escalation_reason = shared.get("escalation_reason", "")
        task_complexity = shared.get("task_complexity", 0)
        
        print(f"ğŸš¨ HumanEscalation: å‡†å¤‡äººå·¥å¹²é¢„")
        print(f"ğŸ“‹ ä»»åŠ¡: {task}")
        print(f"ğŸ“Œ å‡çº§åŸå› : {escalation_reason}")
        print(f"ğŸ“Š å¤æ‚åº¦: {task_complexity:.2f}")
        
        return {
            "task": task,
            "escalation_reason": escalation_reason,
            "task_complexity": task_complexity
        }
    
    def exec(self, prep_res):
        """æ‰§è¡Œé˜¶æ®µï¼šå¤„ç†å‡çº§é€»è¾‘"""
        task = prep_res.get("task", "")
        escalation_reason = prep_res.get("escalation_reason", "")
        task_complexity = prep_res.get("task_complexity", 0)
        
        # å‡†å¤‡äººå·¥å¹²é¢„æ‰€éœ€çš„ä¿¡æ¯
        escalation_info = {
            "task": task,
            "complexity": task_complexity,
            "reason": escalation_reason,
            "timestamp": time.time(),
            "status": "pending_human_input"
        }
        
        # ç”Ÿæˆäººå·¥å¹²é¢„è¯·æ±‚
        print("ğŸ“ HumanEscalation: ç”Ÿæˆäººå·¥å¹²é¢„è¯·æ±‚...")
        escalation_request = self._generate_escalation_request(task, escalation_reason, task_complexity)
        
        print("ğŸ”„ HumanEscalation: ç­‰å¾…äººå·¥è¾“å…¥...")
        
        return {
            "action": "request_human_input",
            "escalation_info": escalation_info,
            "escalation_request": escalation_request
        }
    
    def post(self, shared, prep_res, exec_res):
        """åå¤„ç†é˜¶æ®µï¼šæ›´æ–°å…±äº«çŠ¶æ€"""
        shared["escalation_info"] = exec_res.get("escalation_info", {})
        shared["human_input_required"] = True
        shared["escalation_request"] = exec_res.get("escalation_request", "")
        
        print("å·²è§¦å‘äººå·¥å¹²é¢„æµç¨‹")
        return exec_res.get("action", "request_human_input")
    
    def _generate_escalation_request(self, task: str, reason: str, complexity: float) -> str:
        """
        ç”Ÿæˆäººå·¥å¹²é¢„è¯·æ±‚
        
        Args:
            task: ä»»åŠ¡æè¿°
            reason: å‡çº§åŸå› 
            complexity: å¤æ‚åº¦åˆ†æ•°
            
        Returns:
            str: äººå·¥å¹²é¢„è¯·æ±‚æ–‡æœ¬
        """
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆä¸€ä¸ªæ¸…æ™°çš„äººå·¥å¹²é¢„è¯·æ±‚ï¼ŒåŒ…æ‹¬ï¼š
        1. ä»»åŠ¡æè¿°
        2. éœ€è¦äººå·¥å¹²é¢„çš„åŸå› 
        3. å»ºè®®çš„äººå·¥å¤„ç†æ–¹å‘
        4. ä»»ä½•ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯
        
        ä»»åŠ¡: {task}
        å¹²é¢„åŸå› : {reason}
        å¤æ‚åº¦è¯„åˆ†: {complexity:.2f}/1.0
        """
        
        return call_llm(prompt)


class HumanInput(Node):
    """äººå·¥è¾“å…¥èŠ‚ç‚¹ - æ¥æ”¶å’Œåˆ†æäººç±»è¾“å…¥"""
    
    def __init__(self):
        super().__init__()
    
    def prep(self, shared):
        # å‡†å¤‡é˜¶æ®µï¼šè·å–äººå·¥è¾“å…¥æ‰€éœ€çš„ä¿¡æ¯
        escalation_info = shared.get("escalation_info", {})
        escalation_request = shared.get("escalation_request", "")
        
        return {
            "escalation_info": escalation_info,
            "escalation_request": escalation_request,
            "task": shared.get("task", ""),
            "task_complexity": shared.get("task_complexity", 0)
        }
    
    def exec(self, prep_res):
        # æ‰§è¡Œé˜¶æ®µï¼šè·å–äººå·¥è¾“å…¥
        escalation_request = prep_res.get("escalation_request", "")
        
        print(f"ğŸ‘¤ è¯·æä¾›äººå·¥è¾“å…¥")
        print(f"ğŸ“‹ è¯·æ±‚è¯¦æƒ…: {escalation_request}")
        
        # æ¨¡æ‹Ÿäººå·¥è¾“å…¥ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½æ˜¯GUIã€APIç­‰ï¼‰
        human_input = self._simulate_human_input(prep_res)
        
        return {
            "action": "process_human_input",
            "human_input": human_input,
            "input_source": "simulated"
        }
    
    def post(self, shared, prep_res, exec_res):
        # åå¤„ç†é˜¶æ®µï¼šæ›´æ–°å…±äº«çŠ¶æ€
        human_input = exec_res.get("human_input", "")
        
        shared["human_input"] = human_input
        if "processing_history" not in shared:
            shared["processing_history"] = []
        shared["processing_history"].append({
            "node": "HumanInput",
            "result": "process_human_input",
            "timestamp": time.time(),
            "human_input": human_input
        })
        
        print(f"âœ… å·²æ¥æ”¶äººå·¥è¾“å…¥: {human_input}")
        return exec_res.get("action", "process_human_input")
    
    def _simulate_human_input(self, shared_data: Dict[str, Any]) -> str:
        """
        æ¨¡æ‹Ÿäººç±»è¾“å…¥ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        Args:
            shared_data: å…±äº«æ•°æ®å­—å…¸
            
        Returns:
            str: æ¨¡æ‹Ÿçš„äººç±»è¾“å…¥
        """
        task = shared_data.get("task", "")
        complexity = shared_data.get("task_complexity", 0)
        
        # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦ç”Ÿæˆä¸åŒè´¨é‡çš„æ¨¡æ‹Ÿè¾“å…¥
        if complexity > 0.8:
            return f"å¯¹äºä»»åŠ¡'{task}'ï¼Œæˆ‘å»ºè®®é‡‡ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š1. é¦–å…ˆåˆ†ææ ¸å¿ƒéœ€æ±‚ 2. åˆ¶å®šè¯¦ç»†è®¡åˆ’ 3. åˆ†æ­¥éª¤æ‰§è¡Œ 4. è®¾ç½®æ£€æŸ¥ç‚¹ã€‚è¿™ä¸ªä»»åŠ¡éœ€è¦è·¨éƒ¨é—¨åä½œï¼Œå»ºè®®æˆç«‹ä¸“é—¨é¡¹ç›®ç»„ã€‚"
        elif complexity > 0.5:
            return f"å…³äºä»»åŠ¡'{task}'ï¼Œæˆ‘è®¤ä¸ºéœ€è¦æ›´å¤šèƒŒæ™¯ä¿¡æ¯ã€‚å»ºè®®å…ˆè¿›è¡Œéœ€æ±‚è°ƒç ”ï¼Œç„¶ååˆ¶å®šåˆæ­¥æ–¹æ¡ˆï¼Œæœ€åæäº¤å®¡æ‰¹ã€‚"
        else:
            return f"ä»»åŠ¡'{task}'å¯ä»¥ç›´æ¥æŒ‰ç…§æ ‡å‡†æµç¨‹å¤„ç†ï¼Œæ— éœ€ç‰¹æ®Šå¹²é¢„ã€‚"
    
    def _analyze_human_input(self, human_input: str) -> Dict[str, Any]:
        """
        åˆ†æäººç±»è¾“å…¥
        
        Args:
            human_input: äººç±»è¾“å…¥æ–‡æœ¬
            
        Returns:
            Dict[str, Any]: è¾“å…¥åˆ†æç»“æœ
        """
        # ç®€å•çš„è¾“å…¥åˆ†æ
        analysis = {
            "length": len(human_input),
            "word_count": len(human_input.split()),
            "has_action_items": "å»ºè®®" in human_input or "åº”è¯¥" in human_input or "éœ€è¦" in human_input,
            "sentiment": "neutral"  # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥ä½¿ç”¨æƒ…æ„Ÿåˆ†æ
        }
        
        # æ ¹æ®å…³é”®è¯åˆ¤æ–­è¾“å…¥ç±»å‹
        if "æ‰¹å‡†" in human_input or "åŒæ„" in human_input:
            analysis["input_type"] = "approval"
        elif "æ‹’ç»" in human_input or "ä¸åŒæ„" in human_input:
            analysis["input_type"] = "rejection"
        elif "ä¿®æ”¹" in human_input or "è°ƒæ•´" in human_input:
            analysis["input_type"] = "modification"
        else:
            analysis["input_type"] = "general_guidance"
        
        return analysis


class ResponseGenerator(Node):
    """å“åº”ç”ŸæˆèŠ‚ç‚¹ - ç”Ÿæˆæœ€ç»ˆå“åº”"""
    
    def __init__(self):
        super().__init__()
    
    def prep(self, shared):
        """å‡†å¤‡é˜¶æ®µï¼šè·å–å“åº”ç”Ÿæˆæ‰€éœ€çš„ä¿¡æ¯"""
        task = shared.get("task", "")
        task_result = shared.get("task_result", None)
        human_input = shared.get("human_input", None)
        requires_human_intervention = shared.get("requires_human_intervention", False)
        
        return {
            "task": task,
            "task_result": task_result,
            "human_input": human_input,
            "requires_human_intervention": requires_human_intervention
        }
    
    def exec(self, prep_res):
        """æ‰§è¡Œé˜¶æ®µï¼šç”Ÿæˆå“åº”"""
        task = prep_res.get("task", "")
        task_result = prep_res.get("task_result", None)
        human_input = prep_res.get("human_input", None)
        requires_human_intervention = prep_res.get("requires_human_intervention", False)
        
        print(f"ğŸ“ ResponseGenerator: ç”Ÿæˆæœ€ç»ˆå“åº”")
        
        if requires_human_intervention:
            # éœ€è¦äººå·¥å¹²é¢„çš„æƒ…å†µ
            human_input_analysis = prep_res.get("human_input_analysis", {})
            
            print("ğŸ¤ ResponseGenerator: æ•´åˆäººå·¥è¾“å…¥ç”Ÿæˆå“åº”")
            response = self._generate_human_integrated_response(task, human_input, human_input_analysis)
            response_type = "human_integrated"
        else:
            # è‡ªåŠ¨å¤„ç†çš„æƒ…å†µ
            print("ğŸ¤– ResponseGenerator: ç”Ÿæˆè‡ªåŠ¨å¤„ç†å“åº”")
            response = self._generate_auto_response(task, task_result or {})
            response_type = "automated"
        
        return {
            "action": "response_generated",
            "response": response,
            "response_type": response_type
        }
    
    def post(self, shared, prep_res, exec_res):
        """åå¤„ç†é˜¶æ®µï¼šæ›´æ–°å…±äº«çŠ¶æ€"""
        response = exec_res.get("response", "")
        response_type = exec_res.get("response_type", "automated")
        
        shared["final_response"] = response
        shared["response_type"] = response_type
        shared["response_timestamp"] = time.time()
        
        if "processing_history" not in shared:
            shared["processing_history"] = []
        shared["processing_history"].append({
            "node": "ResponseGenerator",
            "result": "response_generated",
            "timestamp": time.time(),
            "response_type": response_type
        })
        
        print("âœ… ResponseGenerator: æœ€ç»ˆå“åº”å·²ç”Ÿæˆ")
        return exec_res.get("action", "response_generated")
    
    def _generate_human_integrated_response(self, task: str, human_input: str, input_analysis: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ•´åˆäººå·¥è¾“å…¥çš„å“åº”
        
        Args:
            task: åŸå§‹ä»»åŠ¡
            human_input: äººç±»è¾“å…¥
            input_analysis: äººç±»è¾“å…¥åˆ†æ
            
        Returns:
            str: æ•´åˆå“åº”
        """
        prompt = f"""
        åŸå§‹ä»»åŠ¡: {task}
        
        äººç±»ä¸“å®¶è¾“å…¥: {human_input}
        
        è¾“å…¥åˆ†æ: {input_analysis}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å“åº”ï¼ŒåŒ…æ‹¬ï¼š
        1. å¯¹ä»»åŠ¡çš„ç†è§£
        2. äººç±»ä¸“å®¶çš„å…³é”®å»ºè®®
        3. æœ€ç»ˆçš„å¤„ç†æ–¹æ¡ˆ
        4. åç»­æ‰§è¡Œæ­¥éª¤
        """
        
        return call_llm(prompt)
    
    def _generate_auto_response(self, task: str, task_result: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆè‡ªåŠ¨å¤„ç†çš„å“åº”
        
        Args:
            task: åŸå§‹ä»»åŠ¡
            task_result: è‡ªåŠ¨å¤„ç†ç»“æœ
            
        Returns:
            str: è‡ªåŠ¨å“åº”
        """
        prompt = f"""
        åŸå§‹ä»»åŠ¡: {task}
        
        è‡ªåŠ¨å¤„ç†ç»“æœ: {task_result.get('response', '')}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å“åº”ï¼Œè¯´æ˜ä»»åŠ¡å·²è‡ªåŠ¨å¤„ç†å®Œæˆï¼Œå¹¶æä¾›å¤„ç†ç»“æœçš„æ‘˜è¦ã€‚
        """
        
        return call_llm(prompt)